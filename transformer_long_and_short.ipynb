{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_array, labels_array):\n",
    "        self.data_array = data_array\n",
    "        self.labels_array = labels_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.data_array[idx]), torch.Tensor([self.labels_array[idx]])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    return torch.stack(data), torch.cat(labels)\n",
    "\n",
    "# Your data processing code here\n",
    "data_root = \"train_data\"\n",
    "data_list = []\n",
    "labels_list = []\n",
    "max_sequence_length = 0\n",
    "\n",
    "for language_folder in os.listdir(data_root):\n",
    "    language_path = os.path.join(data_root, language_folder)\n",
    "\n",
    "    if os.path.isdir(language_path):\n",
    "        for npy_file in os.listdir(language_path):\n",
    "            if npy_file.endswith(\".npy\"):\n",
    "                npy_path = os.path.join(language_path, npy_file)\n",
    "                data = np.load(npy_path)\n",
    "                max_sequence_length = max(max_sequence_length, data.shape[0])\n",
    "                data_list.append(data)\n",
    "                labels_list.append(int(language_folder.split('_')[-1]))\n",
    "\n",
    "test_root = \"test_data\"\n",
    "test_list = []\n",
    "for npy_file in os.listdir(test_root):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "            npy_path = os.path.join(test_root, npy_file)\n",
    "            test = np.load(npy_path)\n",
    "            max_sequence_length = max(max_sequence_length, test.shape[0])\n",
    "            test_list.append(test)\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    current_sequence_length = data_list[i].shape[0]\n",
    "    if current_sequence_length < max_sequence_length:\n",
    "        pad_length = max_sequence_length - current_sequence_length\n",
    "        data_list[i] = np.pad(data_list[i], ((0, pad_length), (0, 0)), 'wrap')\n",
    "\n",
    "for i in range(len(test_list)):\n",
    "    current_sequence_length = test_list[i].shape[0]\n",
    "    if current_sequence_length < max_sequence_length:\n",
    "        pad_length = max_sequence_length - current_sequence_length\n",
    "        test_list[i] = np.pad(test_list[i], ((0, pad_length), (0, 0)), 'wrap')\n",
    "\n",
    "data_array = np.array(data_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "test_array = np.array(test_list)\n",
    "test_tensor = torch.tensor(test_array)\n",
    "\n",
    "# Create a dataset\n",
    "dataset = CustomDataset(data_array, labels_array)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\big_data\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "Epoch [1/50], Loss: 0.6330, Validation Accuracy: 60.00%\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "Epoch [2/50], Loss: 0.7016, Validation Accuracy: 64.12%\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "Epoch [3/50], Loss: 0.7656, Validation Accuracy: 67.25%\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "Epoch [4/50], Loss: 0.4889, Validation Accuracy: 71.50%\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n",
      "torch.Size([1, 32, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_data, batch_labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# Move data to GPU\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m         batch_data, batch_labels \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, batch_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m     57\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(batch_data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "feature_size = 80  # Assuming 80 features in your data\n",
    "sequence_length = max_sequence_length\n",
    "hidden_size = 128\n",
    "num_classes = 2\n",
    "\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size, num_classes, num_heads=4, num_encoder_layers=10, dropout=0.3):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        out_channels = 256\n",
    "        kernel_size = 5\n",
    "        self.conv1d = nn.Conv1d(in_channels=sequence_length, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        self.relu = nn.SELU()\n",
    "        self.embedding = nn.Linear(out_channels * (feature_size - kernel_size + 1), hidden_size)\n",
    "\n",
    "        self.transformer_encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size, nhead=num_heads, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_encoder_layers, num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1d(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(-1, x.shape[0], x.shape[1])\n",
    "        output = self.transformer_encoder(x)\n",
    "        output = output.view(output.shape[1], -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Move the model to GPU\n",
    "model = TransformerClassifier(hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        # Move data to GPU\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for val_data, val_labels in val_loader:\n",
    "            # Move validation data to GPU\n",
    "            val_data, val_labels = val_data.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_data)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels.long()).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {100 * accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_array, labels_array):\n",
    "        self.data_array = data_array\n",
    "        self.labels_array = labels_array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_array)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.Tensor(self.data_array[idx]), torch.Tensor([self.labels_array[idx]])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "    return torch.stack(data), torch.cat(labels)\n",
    "\n",
    "# Your data processing code here\n",
    "data_root = \"train_data\"\n",
    "data_list = []\n",
    "labels_list = []\n",
    "max_sequence_length = 0\n",
    "min_sequence_length = 10000\n",
    "\n",
    "for language_folder in os.listdir(data_root):\n",
    "    language_path = os.path.join(data_root, language_folder)\n",
    "\n",
    "    if os.path.isdir(language_path):\n",
    "        for npy_file in os.listdir(language_path):\n",
    "            if npy_file.endswith(\".npy\"):\n",
    "                npy_path = os.path.join(language_path, npy_file)\n",
    "                data = np.load(npy_path)\n",
    "                max_sequence_length = max(max_sequence_length, data.shape[0])\n",
    "                min_sequence_length = min(min_sequence_length, data.shape[0])\n",
    "                data_list.append(data)\n",
    "                labels_list.append(int(language_folder.split('_')[-1]))\n",
    "\n",
    "test_root = \"test_data\"\n",
    "test_list = []\n",
    "for npy_file in os.listdir(test_root):\n",
    "    if npy_file.endswith(\".npy\"):\n",
    "            npy_path = os.path.join(test_root, npy_file)\n",
    "            test = np.load(npy_path)\n",
    "            max_sequence_length = max(max_sequence_length, test.shape[0])\n",
    "            min_sequence_length = min(min_sequence_length, test.shape[0])\n",
    "            test_list.append(test)\n",
    "\n",
    "for i in range(len(data_list)):\n",
    "    current_sequence_length = data_list[i].shape[0]\n",
    "    if current_sequence_length > min_sequence_length:\n",
    "        data_list[i] = data_list[i][:min_sequence_length, :]\n",
    "\n",
    "for i in range(len(test_list)):\n",
    "    current_sequence_length = test_list[i].shape[0]\n",
    "    if current_sequence_length > min_sequence_length:\n",
    "        test_list[i] = test_list[i][:min_sequence_length,:]\n",
    "\n",
    "data_array = np.array(data_list)\n",
    "labels_array = np.array(labels_list)\n",
    "\n",
    "test_array = np.array(test_list)\n",
    "test_tensor = torch.tensor(test_array)\n",
    "\n",
    "# Create a dataset\n",
    "dataset = CustomDataset(data_array, labels_array)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "total_samples = len(dataset)\n",
    "train_size = int(0.8 * total_samples)\n",
    "val_size = total_samples - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last=False)\n",
    "\n",
    "test_loader = DataLoader(test_tensor, batch_size=batch_size, shuffle=False,drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\big_data\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6843, Validation Accuracy: 69.38%\n",
      "Epoch [2/100], Loss: 0.4639, Validation Accuracy: 70.75%\n",
      "Epoch [3/100], Loss: 0.6886, Validation Accuracy: 74.38%\n",
      "Epoch [4/100], Loss: 0.5892, Validation Accuracy: 81.00%\n",
      "Epoch [5/100], Loss: 0.2976, Validation Accuracy: 84.88%\n",
      "Epoch [6/100], Loss: 0.3876, Validation Accuracy: 86.12%\n",
      "Epoch [7/100], Loss: 0.1351, Validation Accuracy: 88.12%\n",
      "Epoch [8/100], Loss: 0.4037, Validation Accuracy: 89.12%\n",
      "Epoch [9/100], Loss: 0.5056, Validation Accuracy: 89.25%\n",
      "Epoch [10/100], Loss: 0.1265, Validation Accuracy: 90.12%\n",
      "Epoch [11/100], Loss: 0.1735, Validation Accuracy: 90.25%\n",
      "Epoch [12/100], Loss: 0.1958, Validation Accuracy: 91.00%\n",
      "Epoch [13/100], Loss: 0.3312, Validation Accuracy: 90.50%\n",
      "Epoch [14/100], Loss: 0.1755, Validation Accuracy: 90.25%\n",
      "Epoch [15/100], Loss: 0.3453, Validation Accuracy: 90.75%\n",
      "Epoch [16/100], Loss: 0.1386, Validation Accuracy: 88.12%\n",
      "Epoch [17/100], Loss: 0.1494, Validation Accuracy: 89.88%\n",
      "Epoch [18/100], Loss: 0.2438, Validation Accuracy: 90.50%\n",
      "Epoch [19/100], Loss: 0.1862, Validation Accuracy: 90.88%\n",
      "Epoch [20/100], Loss: 0.2577, Validation Accuracy: 90.50%\n",
      "Epoch [21/100], Loss: 0.3100, Validation Accuracy: 91.38%\n",
      "Epoch [22/100], Loss: 0.1046, Validation Accuracy: 91.12%\n",
      "Epoch [23/100], Loss: 0.1444, Validation Accuracy: 91.38%\n",
      "Epoch [24/100], Loss: 0.1376, Validation Accuracy: 88.88%\n",
      "Epoch [25/100], Loss: 0.2558, Validation Accuracy: 89.88%\n",
      "Epoch [26/100], Loss: 0.1752, Validation Accuracy: 90.88%\n",
      "Epoch [27/100], Loss: 0.1591, Validation Accuracy: 92.00%\n",
      "Epoch [28/100], Loss: 0.1517, Validation Accuracy: 90.88%\n",
      "Epoch [29/100], Loss: 0.1856, Validation Accuracy: 92.00%\n",
      "Epoch [30/100], Loss: 0.1545, Validation Accuracy: 91.38%\n",
      "Epoch [31/100], Loss: 0.2358, Validation Accuracy: 91.62%\n",
      "Epoch [32/100], Loss: 0.1933, Validation Accuracy: 92.75%\n",
      "Epoch [33/100], Loss: 0.0542, Validation Accuracy: 92.12%\n",
      "Epoch [34/100], Loss: 0.0784, Validation Accuracy: 92.62%\n",
      "Epoch [35/100], Loss: 0.1349, Validation Accuracy: 92.38%\n",
      "Epoch [36/100], Loss: 0.1702, Validation Accuracy: 93.25%\n",
      "Epoch [37/100], Loss: 0.3167, Validation Accuracy: 93.00%\n",
      "Epoch [38/100], Loss: 0.1846, Validation Accuracy: 92.00%\n",
      "Epoch [39/100], Loss: 0.1665, Validation Accuracy: 93.00%\n",
      "Epoch [40/100], Loss: 0.3006, Validation Accuracy: 93.00%\n",
      "Epoch [41/100], Loss: 0.1120, Validation Accuracy: 93.00%\n",
      "Epoch [42/100], Loss: 0.0694, Validation Accuracy: 93.50%\n",
      "Epoch [43/100], Loss: 0.1227, Validation Accuracy: 91.75%\n",
      "Epoch [44/100], Loss: 0.0863, Validation Accuracy: 92.75%\n",
      "Epoch [45/100], Loss: 0.0857, Validation Accuracy: 93.38%\n",
      "Epoch [46/100], Loss: 0.2185, Validation Accuracy: 93.00%\n",
      "Epoch [47/100], Loss: 0.2889, Validation Accuracy: 86.50%\n",
      "Epoch [48/100], Loss: 0.0574, Validation Accuracy: 92.38%\n",
      "Epoch [49/100], Loss: 0.1822, Validation Accuracy: 93.12%\n",
      "Epoch [50/100], Loss: 0.0220, Validation Accuracy: 92.50%\n",
      "Epoch [51/100], Loss: 0.0482, Validation Accuracy: 92.75%\n",
      "Epoch [52/100], Loss: 0.2651, Validation Accuracy: 92.75%\n",
      "Epoch [53/100], Loss: 0.1302, Validation Accuracy: 90.88%\n",
      "Epoch [54/100], Loss: 0.1735, Validation Accuracy: 93.00%\n",
      "Epoch [55/100], Loss: 0.0585, Validation Accuracy: 92.38%\n",
      "Epoch [56/100], Loss: 0.0510, Validation Accuracy: 93.38%\n",
      "Epoch [57/100], Loss: 0.0475, Validation Accuracy: 93.25%\n",
      "Epoch [58/100], Loss: 0.3363, Validation Accuracy: 92.88%\n",
      "Epoch [59/100], Loss: 0.0755, Validation Accuracy: 93.88%\n",
      "Epoch [60/100], Loss: 0.1622, Validation Accuracy: 93.62%\n",
      "Epoch [61/100], Loss: 0.1458, Validation Accuracy: 93.88%\n",
      "Epoch [62/100], Loss: 0.0248, Validation Accuracy: 93.38%\n",
      "Epoch [63/100], Loss: 0.1390, Validation Accuracy: 93.38%\n",
      "Epoch [64/100], Loss: 0.3211, Validation Accuracy: 93.00%\n",
      "Epoch [65/100], Loss: 0.0704, Validation Accuracy: 93.88%\n",
      "Epoch [66/100], Loss: 0.0506, Validation Accuracy: 92.75%\n",
      "Epoch [67/100], Loss: 0.1749, Validation Accuracy: 93.50%\n",
      "Epoch [68/100], Loss: 0.3798, Validation Accuracy: 93.25%\n",
      "Epoch [69/100], Loss: 0.1499, Validation Accuracy: 93.62%\n",
      "Epoch [70/100], Loss: 0.2495, Validation Accuracy: 93.50%\n",
      "Epoch [71/100], Loss: 0.1950, Validation Accuracy: 93.75%\n",
      "Epoch [72/100], Loss: 0.0829, Validation Accuracy: 93.62%\n",
      "Epoch [73/100], Loss: 0.1101, Validation Accuracy: 93.88%\n",
      "Epoch [74/100], Loss: 0.1901, Validation Accuracy: 93.75%\n",
      "Epoch [75/100], Loss: 0.1902, Validation Accuracy: 90.75%\n",
      "Epoch [76/100], Loss: 0.0150, Validation Accuracy: 94.12%\n",
      "Epoch [77/100], Loss: 0.0653, Validation Accuracy: 93.38%\n",
      "Epoch [78/100], Loss: 0.0948, Validation Accuracy: 94.00%\n",
      "Epoch [79/100], Loss: 0.0375, Validation Accuracy: 93.88%\n",
      "Epoch [80/100], Loss: 0.1514, Validation Accuracy: 94.00%\n",
      "Epoch [81/100], Loss: 0.1227, Validation Accuracy: 93.12%\n",
      "Epoch [82/100], Loss: 0.2061, Validation Accuracy: 94.25%\n",
      "Epoch [83/100], Loss: 0.1160, Validation Accuracy: 93.75%\n",
      "Epoch [84/100], Loss: 0.0583, Validation Accuracy: 93.88%\n",
      "Epoch [85/100], Loss: 0.3763, Validation Accuracy: 93.12%\n",
      "Epoch [86/100], Loss: 0.2188, Validation Accuracy: 93.38%\n",
      "Epoch [87/100], Loss: 0.0456, Validation Accuracy: 94.25%\n",
      "Epoch [88/100], Loss: 0.1017, Validation Accuracy: 91.50%\n",
      "Epoch [89/100], Loss: 0.1013, Validation Accuracy: 93.88%\n",
      "Epoch [90/100], Loss: 0.1210, Validation Accuracy: 93.75%\n",
      "Epoch [91/100], Loss: 0.1795, Validation Accuracy: 93.88%\n",
      "Epoch [92/100], Loss: 0.0682, Validation Accuracy: 94.00%\n",
      "Epoch [93/100], Loss: 0.1374, Validation Accuracy: 93.88%\n",
      "Epoch [94/100], Loss: 0.2327, Validation Accuracy: 91.00%\n",
      "Epoch [95/100], Loss: 0.0662, Validation Accuracy: 93.38%\n",
      "Epoch [96/100], Loss: 0.0446, Validation Accuracy: 94.38%\n",
      "Epoch [97/100], Loss: 0.1712, Validation Accuracy: 92.12%\n",
      "Epoch [98/100], Loss: 0.0320, Validation Accuracy: 93.25%\n",
      "Epoch [99/100], Loss: 0.0308, Validation Accuracy: 93.88%\n",
      "Epoch [100/100], Loss: 0.1102, Validation Accuracy: 93.50%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "feature_size = 80  # Assuming 80 features in your data\n",
    "sequence_length = min_sequence_length\n",
    "\n",
    "\n",
    "model_params = {\n",
    "        'hidden_size': 128,\n",
    "        'num_heads': 4,\n",
    "        'num_encoder_layers': 4,\n",
    "        'dropout': 0.3,\n",
    "        'out_channels': 32,\n",
    "        'kernel_size': 3\n",
    "    }\n",
    "\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_heads=4, num_encoder_layers=4, dropout=0.3, out_channels=32, kernel_size=3):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=sequence_length, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        self.relu = nn.SELU()\n",
    "        self.embedding = nn.Linear(out_channels * (feature_size - kernel_size + 1), hidden_size)\n",
    "\n",
    "        self.transformer_encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size, nhead=num_heads, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            self.transformer_encoder_layers, num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1d(x))\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.embedding(x)\n",
    "        x = x.view(-1, x.shape[0], x.shape[1])\n",
    "        output = self.transformer_encoder(x)\n",
    "        output = output.view(output.shape[1], -1)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Move the model to GPU\n",
    "model = TransformerClassifier().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_data, batch_labels in train_loader:\n",
    "        # Move data to GPU\n",
    "        batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(batch_data)\n",
    "        loss = criterion(outputs, batch_labels.long())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    # Validation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for val_data, val_labels in val_loader:\n",
    "            # Move validation data to GPU\n",
    "            val_data, val_labels = val_data.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_data)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels.long()).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {100 * accuracy:.2f}%')\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'save_models/'+'model_transformer_v1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\big_data\\lib\\site-packages\\torch\\nn\\modules\\transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "test_label = []\n",
    "model = TransformerClassifier().to(device)\n",
    "model.load_state_dict(torch.load('save_models/model_transformer_v1.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        # Move validation data to GPU\n",
    "        test_data = test_data.to(device)\n",
    "\n",
    "        test_outputs = model(test_data)\n",
    "        _, predicted = torch.max(test_outputs.data, 1)\n",
    "        \n",
    "        test_label.extend(predicted.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "927"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:03:12,405] A new study created in memory with name: no-name-d76b1ec4-5c14-4054-bc79-86747e044d41\n",
      "[I 2023-12-22 22:05:55,981] Trial 0 finished with value: 0.9375 and parameters: {'hidden_size': 66, 'num_heads': 3, 'num_encoder_layers': 5, 'dropout': 0.26792001323294157, 'out_channels': 60, 'kernel_size': 6}. Best is trial 0 with value: 0.9375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66_3_5_0.26792001323294157_60_6_Validation Accuracy: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:09:35,110] Trial 1 finished with value: 0.9425 and parameters: {'hidden_size': 133, 'num_heads': 5, 'num_encoder_layers': 7, 'dropout': 0.34948548858777095, 'out_channels': 39, 'kernel_size': 6}. Best is trial 1 with value: 0.9425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130_5_7_0.34948548858777095_39_6_Validation Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:13:48,738] Trial 2 finished with value: 0.93625 and parameters: {'hidden_size': 201, 'num_heads': 3, 'num_encoder_layers': 7, 'dropout': 0.15005351812746826, 'out_channels': 21, 'kernel_size': 6}. Best is trial 1 with value: 0.9425.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201_3_7_0.15005351812746826_21_6_Validation Accuracy: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:16:06,490] Trial 3 finished with value: 0.9475 and parameters: {'hidden_size': 141, 'num_heads': 8, 'num_encoder_layers': 4, 'dropout': 0.244532796804605, 'out_channels': 30, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136_8_4_0.244532796804605_30_3_Validation Accuracy: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:19:47,607] Trial 4 finished with value: 0.93125 and parameters: {'hidden_size': 204, 'num_heads': 4, 'num_encoder_layers': 6, 'dropout': 0.3692458582355137, 'out_channels': 17, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204_4_6_0.3692458582355137_17_3_Validation Accuracy: 93.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:24:00,950] Trial 5 finished with value: 0.93 and parameters: {'hidden_size': 158, 'num_heads': 4, 'num_encoder_layers': 7, 'dropout': 0.479715076645308, 'out_channels': 61, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156_4_7_0.479715076645308_61_3_Validation Accuracy: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:25:21,761] Trial 6 finished with value: 0.93875 and parameters: {'hidden_size': 64, 'num_heads': 8, 'num_encoder_layers': 2, 'dropout': 0.4753559428591169, 'out_channels': 51, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64_8_2_0.4753559428591169_51_3_Validation Accuracy: 93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:27:36,622] Trial 7 finished with value: 0.91 and parameters: {'hidden_size': 80, 'num_heads': 3, 'num_encoder_layers': 4, 'dropout': 0.027067144476562277, 'out_channels': 16, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78_3_4_0.027067144476562277_16_3_Validation Accuracy: 91.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:29:17,189] Trial 8 finished with value: 0.945 and parameters: {'hidden_size': 186, 'num_heads': 3, 'num_encoder_layers': 2, 'dropout': 0.05692433040038153, 'out_channels': 54, 'kernel_size': 3}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186_3_2_0.05692433040038153_54_3_Validation Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:30:44,889] Trial 9 finished with value: 0.93 and parameters: {'hidden_size': 119, 'num_heads': 7, 'num_encoder_layers': 2, 'dropout': 0.38035107113508826, 'out_channels': 40, 'kernel_size': 7}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119_7_2_0.38035107113508826_40_7_Validation Accuracy: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:33:43,052] Trial 10 finished with value: 0.9475 and parameters: {'hidden_size': 234, 'num_heads': 7, 'num_encoder_layers': 4, 'dropout': 0.16365174865789361, 'out_channels': 30, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231_7_4_0.16365174865789361_30_4_Validation Accuracy: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:36:45,775] Trial 11 finished with value: 0.93625 and parameters: {'hidden_size': 254, 'num_heads': 7, 'num_encoder_layers': 4, 'dropout': 0.18315978673287775, 'out_channels': 29, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252_7_4_0.18315978673287775_29_4_Validation Accuracy: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:39:46,029] Trial 12 finished with value: 0.92 and parameters: {'hidden_size': 253, 'num_heads': 8, 'num_encoder_layers': 4, 'dropout': 0.1763742996626421, 'out_channels': 31, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248_8_4_0.1763742996626421_31_4_Validation Accuracy: 92.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:41:39,879] Trial 13 finished with value: 0.935 and parameters: {'hidden_size': 113, 'num_heads': 6, 'num_encoder_layers': 3, 'dropout': 0.26028203134323874, 'out_channels': 29, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108_6_3_0.26028203134323874_29_4_Validation Accuracy: 93.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:44:48,672] Trial 14 finished with value: 0.94 and parameters: {'hidden_size': 164, 'num_heads': 7, 'num_encoder_layers': 5, 'dropout': 0.09027774302975328, 'out_channels': 33, 'kernel_size': 5}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161_7_5_0.09027774302975328_33_5_Validation Accuracy: 94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:47:06,932] Trial 15 finished with value: 0.93875 and parameters: {'hidden_size': 229, 'num_heads': 6, 'num_encoder_layers': 3, 'dropout': 0.12200015310323972, 'out_channels': 24, 'kernel_size': 5}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228_6_3_0.12200015310323972_24_5_Validation Accuracy: 93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:50:45,013] Trial 16 finished with value: 0.94625 and parameters: {'hidden_size': 154, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.23436036147125466, 'out_channels': 45, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152_8_6_0.23436036147125466_45_4_Validation Accuracy: 94.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:52:36,378] Trial 17 finished with value: 0.94375 and parameters: {'hidden_size': 98, 'num_heads': 6, 'num_encoder_layers': 3, 'dropout': 0.2254157693110258, 'out_channels': 38, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96_6_3_0.2254157693110258_38_4_Validation Accuracy: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 22:55:29,536] Trial 18 finished with value: 0.94375 and parameters: {'hidden_size': 225, 'num_heads': 7, 'num_encoder_layers': 4, 'dropout': 0.30438458173033317, 'out_channels': 24, 'kernel_size': 5}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224_7_4_0.30438458173033317_24_5_Validation Accuracy: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:00:19,937] Trial 19 finished with value: 0.94125 and parameters: {'hidden_size': 177, 'num_heads': 8, 'num_encoder_layers': 8, 'dropout': 0.10732803913523015, 'out_channels': 35, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176_8_8_0.10732803913523015_35_4_Validation Accuracy: 94.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:03:21,932] Trial 20 finished with value: 0.9375 and parameters: {'hidden_size': 136, 'num_heads': 5, 'num_encoder_layers': 5, 'dropout': 0.323079062743848, 'out_channels': 45, 'kernel_size': 5}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135_5_5_0.323079062743848_45_5_Validation Accuracy: 93.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:06:56,700] Trial 21 finished with value: 0.9475 and parameters: {'hidden_size': 151, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.21063163161580706, 'out_channels': 46, 'kernel_size': 4}. Best is trial 3 with value: 0.9475.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144_8_6_0.21063163161580706_46_4_Validation Accuracy: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:10:27,764] Trial 22 finished with value: 0.94875 and parameters: {'hidden_size': 142, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.19000193056035242, 'out_channels': 45, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136_8_6_0.19000193056035242_45_3_Validation Accuracy: 94.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:13:26,951] Trial 23 finished with value: 0.93875 and parameters: {'hidden_size': 135, 'num_heads': 7, 'num_encoder_layers': 5, 'dropout': 0.16655303357074658, 'out_channels': 26, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133_7_5_0.16655303357074658_26_3_Validation Accuracy: 93.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:16:41,820] Trial 24 finished with value: 0.92375 and parameters: {'hidden_size': 101, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.2754856912917151, 'out_channels': 35, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96_8_6_0.2754856912917151_35_3_Validation Accuracy: 92.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:19:25,842] Trial 25 finished with value: 0.9175 and parameters: {'hidden_size': 180, 'num_heads': 2, 'num_encoder_layers': 4, 'dropout': 0.41984858966999744, 'out_channels': 49, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180_2_4_0.41984858966999744_49_3_Validation Accuracy: 91.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:21:22,405] Trial 26 finished with value: 0.9475 and parameters: {'hidden_size': 122, 'num_heads': 6, 'num_encoder_layers': 3, 'dropout': 0.20037904909613158, 'out_channels': 42, 'kernel_size': 4}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120_6_3_0.20037904909613158_42_4_Validation Accuracy: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:26:27,127] Trial 27 finished with value: 0.9475 and parameters: {'hidden_size': 199, 'num_heads': 7, 'num_encoder_layers': 8, 'dropout': 0.07139888813206152, 'out_channels': 55, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196_7_8_0.07139888813206152_55_3_Validation Accuracy: 94.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:29:59,655] Trial 28 finished with value: 0.9075 and parameters: {'hidden_size': 232, 'num_heads': 8, 'num_encoder_layers': 5, 'dropout': 0.13471005870810232, 'out_channels': 36, 'kernel_size': 3}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232_8_5_0.13471005870810232_36_3_Validation Accuracy: 90.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:33:13,885] Trial 29 finished with value: 0.93 and parameters: {'hidden_size': 170, 'num_heads': 7, 'num_encoder_layers': 5, 'dropout': 0.28956801716130537, 'out_channels': 64, 'kernel_size': 7}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168_7_5_0.28956801716130537_64_7_Validation Accuracy: 93.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:35:45,058] Trial 30 finished with value: 0.93375 and parameters: {'hidden_size': 145, 'num_heads': 5, 'num_encoder_layers': 4, 'dropout': 0.011638093752502993, 'out_channels': 21, 'kernel_size': 4}. Best is trial 22 with value: 0.94875.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145_5_4_0.011638093752502993_21_4_Validation Accuracy: 93.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:39:18,590] Trial 31 finished with value: 0.95 and parameters: {'hidden_size': 148, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.21008686491134282, 'out_channels': 45, 'kernel_size': 5}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144_8_6_0.21008686491134282_45_5_Validation Accuracy: 95.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:42:44,820] Trial 32 finished with value: 0.94 and parameters: {'hidden_size': 144, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.25007419908212886, 'out_channels': 42, 'kernel_size': 6}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144_8_6_0.25007419908212886_42_6_Validation Accuracy: 94.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:46:19,898] Trial 33 finished with value: 0.91125 and parameters: {'hidden_size': 127, 'num_heads': 8, 'num_encoder_layers': 7, 'dropout': 0.20226331277270612, 'out_channels': 51, 'kernel_size': 6}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120_8_7_0.20226331277270612_51_6_Validation Accuracy: 91.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:49:19,242] Trial 34 finished with value: 0.945 and parameters: {'hidden_size': 107, 'num_heads': 7, 'num_encoder_layers': 6, 'dropout': 0.15891541002406873, 'out_channels': 39, 'kernel_size': 5}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105_7_6_0.15891541002406873_39_5_Validation Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:52:10,194] Trial 35 finished with value: 0.94375 and parameters: {'hidden_size': 167, 'num_heads': 8, 'num_encoder_layers': 5, 'dropout': 0.33052717394405035, 'out_channels': 47, 'kernel_size': 5}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160_8_5_0.33052717394405035_47_5_Validation Accuracy: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:55:32,170] Trial 36 finished with value: 0.935 and parameters: {'hidden_size': 87, 'num_heads': 6, 'num_encoder_layers': 7, 'dropout': 0.23550378106056524, 'out_channels': 32, 'kernel_size': 3}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84_6_7_0.23550378106056524_32_3_Validation Accuracy: 93.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-22 23:59:08,913] Trial 37 finished with value: 0.93375 and parameters: {'hidden_size': 191, 'num_heads': 7, 'num_encoder_layers': 6, 'dropout': 0.18555091824141792, 'out_channels': 42, 'kernel_size': 4}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189_7_6_0.18555091824141792_42_4_Validation Accuracy: 93.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:03:26,573] Trial 38 finished with value: 0.945 and parameters: {'hidden_size': 214, 'num_heads': 4, 'num_encoder_layers': 7, 'dropout': 0.13810151225177458, 'out_channels': 57, 'kernel_size': 3}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212_4_7_0.13810151225177458_57_3_Validation Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:05:48,953] Trial 39 finished with value: 0.9425 and parameters: {'hidden_size': 140, 'num_heads': 8, 'num_encoder_layers': 4, 'dropout': 0.10331907250663103, 'out_channels': 28, 'kernel_size': 6}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136_8_4_0.10331907250663103_28_6_Validation Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:08:55,843] Trial 40 finished with value: 0.88625 and parameters: {'hidden_size': 159, 'num_heads': 8, 'num_encoder_layers': 5, 'dropout': 0.27328649775000335, 'out_channels': 49, 'kernel_size': 5}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152_8_5_0.27328649775000335_49_5_Validation Accuracy: 88.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:12:28,702] Trial 41 finished with value: 0.9425 and parameters: {'hidden_size': 150, 'num_heads': 8, 'num_encoder_layers': 6, 'dropout': 0.21741851228794914, 'out_channels': 45, 'kernel_size': 4}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144_8_6_0.21741851228794914_45_4_Validation Accuracy: 94.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:16:22,530] Trial 42 finished with value: 0.92375 and parameters: {'hidden_size': 127, 'num_heads': 8, 'num_encoder_layers': 7, 'dropout': 0.20071267946786414, 'out_channels': 43, 'kernel_size': 3}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120_8_7_0.20071267946786414_43_3_Validation Accuracy: 92.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:20:16,245] Trial 43 finished with value: 0.94625 and parameters: {'hidden_size': 154, 'num_heads': 7, 'num_encoder_layers': 6, 'dropout': 0.15876154890751998, 'out_channels': 52, 'kernel_size': 4}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154_7_6_0.15876154890751998_52_4_Validation Accuracy: 94.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:23:50,082] Trial 44 finished with value: 0.945 and parameters: {'hidden_size': 176, 'num_heads': 8, 'num_encoder_layers': 5, 'dropout': 0.25544134107126365, 'out_channels': 48, 'kernel_size': 3}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176_8_5_0.25544134107126365_48_3_Validation Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:27:16,060] Trial 45 finished with value: 0.94375 and parameters: {'hidden_size': 116, 'num_heads': 7, 'num_encoder_layers': 6, 'dropout': 0.21300715229741393, 'out_channels': 19, 'kernel_size': 4}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112_7_6_0.21300715229741393_19_4_Validation Accuracy: 94.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:29:19,242] Trial 46 finished with value: 0.945 and parameters: {'hidden_size': 147, 'num_heads': 8, 'num_encoder_layers': 3, 'dropout': 0.17350554667548507, 'out_channels': 39, 'kernel_size': 5}. Best is trial 31 with value: 0.95.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144_8_3_0.17350554667548507_39_5_Validation Accuracy: 94.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:31:59,368] Trial 47 finished with value: 0.9525 and parameters: {'hidden_size': 161, 'num_heads': 8, 'num_encoder_layers': 4, 'dropout': 0.1416134672882693, 'out_channels': 37, 'kernel_size': 3}. Best is trial 47 with value: 0.9525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160_8_4_0.1416134672882693_37_3_Validation Accuracy: 95.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:35:00,735] Trial 48 finished with value: 0.93625 and parameters: {'hidden_size': 242, 'num_heads': 7, 'num_encoder_layers': 4, 'dropout': 0.14264517872164809, 'out_channels': 30, 'kernel_size': 3}. Best is trial 47 with value: 0.9525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238_7_4_0.14264517872164809_30_3_Validation Accuracy: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-23 00:37:47,230] Trial 49 finished with value: 0.93875 and parameters: {'hidden_size': 189, 'num_heads': 6, 'num_encoder_layers': 4, 'dropout': 0.06634575697243457, 'out_channels': 33, 'kernel_size': 3}. Best is trial 47 with value: 0.9525.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186_6_4_0.06634575697243457_33_3_Validation Accuracy: 93.88%\n",
      "Best hyperparameters: {'hidden_size': 161, 'num_heads': 8, 'num_encoder_layers': 4, 'dropout': 0.1416134672882693, 'out_channels': 37, 'kernel_size': 3}\n",
      "Best value (accuracy): 0.9525\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    hidden_size = trial.suggest_int('hidden_size', 64, 256)\n",
    "    num_heads = trial.suggest_int('num_heads', 2, 8)\n",
    "    num_encoder_layers = trial.suggest_int('num_encoder_layers', 2, 8)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    out_channels = trial.suggest_int('out_channels', 16, 64)\n",
    "    kernel_size = trial.suggest_int('kernel_size', 3, 7)\n",
    "\n",
    "    if hidden_size % num_heads != 0:\n",
    "        hidden_size = (hidden_size // num_heads) * num_heads\n",
    "\n",
    "    model = TransformerClassifier(\n",
    "        hidden_size=hidden_size,\n",
    "        num_heads=num_heads,\n",
    "        num_encoder_layers=num_encoder_layers,\n",
    "        dropout=dropout,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=kernel_size\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "    num_epochs = 100\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_data, batch_labels in train_loader:\n",
    "            # Move data to GPU\n",
    "            batch_data, batch_labels = batch_data.to(device), batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_data)\n",
    "            loss = criterion(outputs, batch_labels.long())\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for val_data, val_labels in val_loader:\n",
    "            # Move validation data to GPU\n",
    "            val_data, val_labels = val_data.to(device), val_labels.to(device)\n",
    "\n",
    "            val_outputs = model(val_data)\n",
    "            _, predicted = torch.max(val_outputs.data, 1)\n",
    "            total += val_labels.size(0)\n",
    "            correct += (predicted == val_labels.long()).sum().item()\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f'{hidden_size}_{num_heads}_{num_encoder_layers}_{dropout}_{out_channels}_{kernel_size}_Validation Accuracy: {100 * accuracy:.2f}%')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'save_models/'+f'model_transformer_{hidden_size}_{num_heads}_{num_encoder_layers}_{dropout}_{out_channels}_{kernel_size}.pth')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize') \n",
    "study.optimize(objective, n_trials=50)  \n",
    "\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value\n",
    "print(f\"Best hyperparameters: {best_params}\")\n",
    "print(f\"Best value (accuracy): {best_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
